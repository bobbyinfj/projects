{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "data= pd.read_csv(r'mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>extroverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts extroverted\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           I\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...           E\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           I\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           I\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...           E"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add a column to specify if extroverted.\n",
    "data['extroverted']= data.type.str[:1]\n",
    "#df['New_Sample'] = df.Sample.str[:1]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many is I vs. E in dataset?\n",
    "data.describe()\n",
    "data['extroverted'].groupby('extroverted').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">extroverted</th>\n",
       "      <th colspan=\"4\" halign=\"left\">posts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENFJ</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>'Sorry, but this is, to put it quite frankly, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENFP</th>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>675</td>\n",
       "      <td>675</td>\n",
       "      <td>675</td>\n",
       "      <td>'The movie even gave itself a pass saying it a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTJ</th>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>'Can anyone suggest useful nonfiction books in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTP</th>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>'I'm an ENTP but I'm going to say that that ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFJ</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>'Yep, I'm ESFJ.  Hooray!  http://i40.tinypic.c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFP</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>'267522|||I've had an office job for almost te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTJ</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>'I'm a 3w2.  I identify with it completely.|||...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTP</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>'8 months have passed since i last took a visi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFJ</th>\n",
       "      <td>1470</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470</td>\n",
       "      <td>'Finally moved and now I live on my own. It fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFP</th>\n",
       "      <td>1832</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1832</td>\n",
       "      <td>1832</td>\n",
       "      <td>1832</td>\n",
       "      <td>'Pyroscope, There's a similar thread..'You kno...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1091</td>\n",
       "      <td>1091</td>\n",
       "      <td>1091</td>\n",
       "      <td>'Biology is real and it's effects are measurab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTP</th>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1304</td>\n",
       "      <td>1304</td>\n",
       "      <td>1304</td>\n",
       "      <td>'I hated gym in school, but I love motor racin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFJ</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>52/100 masculine 53/100 feminine 55/100 androg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFP</th>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>For me, friendships are very casual. I am good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTJ</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>'First, apologize for adding the the Necro pos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTP</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>'Fuck me, climbing out of this hole I dug myse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     extroverted                  posts         \\\n",
       "           count unique top  freq count unique   \n",
       "type                                             \n",
       "ENFJ         190      1   E   190   190    190   \n",
       "ENFP         675      1   E   675   675    675   \n",
       "ENTJ         231      1   E   231   231    231   \n",
       "ENTP         685      1   E   685   685    685   \n",
       "ESFJ          42      1   E    42    42     42   \n",
       "ESFP          48      1   E    48    48     48   \n",
       "ESTJ          39      1   E    39    39     39   \n",
       "ESTP          89      1   E    89    89     89   \n",
       "INFJ        1470      1   I  1470  1470   1470   \n",
       "INFP        1832      1   I  1832  1832   1832   \n",
       "INTJ        1091      1   I  1091  1091   1091   \n",
       "INTP        1304      1   I  1304  1304   1304   \n",
       "ISFJ         166      1   I   166   166    166   \n",
       "ISFP         271      1   I   271   271    271   \n",
       "ISTJ         205      1   I   205   205    205   \n",
       "ISTP         337      1   I   337   337    337   \n",
       "\n",
       "                                                              \n",
       "                                                    top freq  \n",
       "type                                                          \n",
       "ENFJ  'Sorry, but this is, to put it quite frankly, ...    1  \n",
       "ENFP  'The movie even gave itself a pass saying it a...    1  \n",
       "ENTJ  'Can anyone suggest useful nonfiction books in...    1  \n",
       "ENTP  'I'm an ENTP but I'm going to say that that ha...    1  \n",
       "ESFJ  'Yep, I'm ESFJ.  Hooray!  http://i40.tinypic.c...    1  \n",
       "ESFP  '267522|||I've had an office job for almost te...    1  \n",
       "ESTJ  'I'm a 3w2.  I identify with it completely.|||...    1  \n",
       "ESTP  '8 months have passed since i last took a visi...    1  \n",
       "INFJ  'Finally moved and now I live on my own. It fe...    1  \n",
       "INFP  'Pyroscope, There's a similar thread..'You kno...    1  \n",
       "INTJ  'Biology is real and it's effects are measurab...    1  \n",
       "INTP  'I hated gym in school, but I love motor racin...    1  \n",
       "ISFJ  52/100 masculine 53/100 feminine 55/100 androg...    1  \n",
       "ISFP  For me, friendships are very casual. I am good...    1  \n",
       "ISTJ  'First, apologize for adding the the Necro pos...    1  \n",
       "ISTP  'Fuck me, climbing out of this hole I dug myse...    1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#breakdown of types in survery\n",
    "type_data = data.groupby('type')\n",
    "type_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>extroverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts extroverted\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           0\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...           1\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           0\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           0\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...           1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['extroverted'].replace(['I','E'],['0','1'],inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type           object\n",
       "posts          object\n",
       "extroverted    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['extroverted'] = data['extroverted'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type           object\n",
       "posts          object\n",
       "extroverted     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(['http', 'isfj', 'infp', 'intj', 'https', 'com', 'youtube', 'enfp', 'entp',\n",
    "                                            'infj', 'infp', 'intj','intp',\n",
    " 'intp','istj', 'istp', '00', 'enfps', 'entps', 'infjs', 'enfjs', 'estps',\n",
    "                                            'entj', 'esfjs', 'existence', 'infps', 'enfj', 'entjs', 'intps', 'estp', 'ne', 'nt', 'ni', 've',\n",
    " '000',\n",
    " '01',\n",
    " '02',\n",
    " '03',\n",
    " '04',\n",
    " '05',\n",
    " '06',\n",
    " '07',\n",
    " '08',\n",
    " '09',\n",
    " '10',\n",
    " '100',\n",
    " '1000',\n",
    " '101',\n",
    " '10th',\n",
    " '11',\n",
    " '110',\n",
    " '11th',\n",
    " '12',\n",
    " '120',\n",
    " '13',\n",
    " '130',\n",
    " '14',\n",
    " '140',\n",
    " '15',\n",
    " '150',\n",
    " '16',\n",
    " '16personalities',\n",
    " '17',\n",
    " '18',\n",
    " '180',\n",
    " '19',\n",
    " '1984',\n",
    " '1995',\n",
    " '1s',\n",
    " '1st',\n",
    " '1w2',\n",
    " '1w9',\n",
    " '20',\n",
    " '200',\n",
    " '2000',\n",
    " '2001',\n",
    " '2005',\n",
    " '2006',\n",
    " '2007',\n",
    " '2008',\n",
    " '2009',\n",
    " '2010',\n",
    " '2011',\n",
    " '2012',\n",
    " '2013',\n",
    " '2014',\n",
    " '2015',\n",
    " '2016',\n",
    " '2017',\n",
    " '20s',\n",
    " '20th',\n",
    " '21',\n",
    " '21st',\n",
    " '22',\n",
    " '23',\n",
    " '24',\n",
    " '25',\n",
    " '26',\n",
    " '27',\n",
    " '28',\n",
    " '29',\n",
    " '2nd',\n",
    " '2w1',\n",
    " '2w3',\n",
    " '30',\n",
    " '300',\n",
    " '30s',\n",
    " '31',\n",
    " '32',\n",
    " '33',\n",
    " '34',\n",
    " '35',\n",
    " '36',\n",
    " '37',\n",
    " '38',\n",
    " '39',\n",
    " '3D',\n",
    " '3rd',\n",
    " '3s',\n",
    " '3w2',\n",
    " '3w4',\n",
    " '40',\n",
    " '400',\n",
    " '41',\n",
    " '42',\n",
    " '43',\n",
    " '44',\n",
    " '45',\n",
    " '46',\n",
    " '47',\n",
    " '48',\n",
    " '49',\n",
    " '4s',\n",
    " '4th',\n",
    " '4w3',\n",
    " '4w5',\n",
    " '50',\n",
    " '500',\n",
    " '51',\n",
    " '52',\n",
    " '53',\n",
    " '54',\n",
    " '55',\n",
    " '56',\n",
    " '564x',\n",
    " '57',\n",
    " '58',\n",
    " '59',\n",
    " '5s',\n",
    " '5th',\n",
    " '5w4',\n",
    " '5w6',\n",
    " '60',\n",
    " '600',\n",
    " '60s',\n",
    " '61',\n",
    " '62',\n",
    " '63',\n",
    " '64',\n",
    " '65',\n",
    " '66',\n",
    " '67',\n",
    " '68',\n",
    " '69',\n",
    " '6s',\n",
    " '6th',\n",
    " '6w5',\n",
    " '6w7',\n",
    " '70',\n",
    " '70s',\n",
    " '71',\n",
    " '72',\n",
    " '73',\n",
    " '736x',\n",
    " '74',\n",
    " '75',\n",
    " '76',\n",
    " '77',\n",
    " '78',\n",
    " '79',\n",
    " '7s',\n",
    " '7th',\n",
    " '7w6',\n",
    " '7w8',\n",
    " '80',\n",
    " '80s',\n",
    " '81',\n",
    " '82',\n",
    " '83',\n",
    " '84',\n",
    " '85',\n",
    " '86',\n",
    " '87',\n",
    " '88',\n",
    " '89',\n",
    " '8s',\n",
    " '8th',\n",
    " '8w7',\n",
    " '8w9',\n",
    " '90',\n",
    " '90s',\n",
    " '91',\n",
    " '92',\n",
    " '94',\n",
    " '95',\n",
    " '98',\n",
    " '99',\n",
    " '9s',\n",
    " '9th',\n",
    " '9w1',\n",
    " '9w8', '125',\n",
    " '160',\n",
    " '2003',\n",
    " '2004',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our count vectorizer\n",
    "count_vectorizer = CountVectorizer(analyzer='word', min_df=100, stop_words = stop_words, lowercase=True)\n",
    "\n",
    "#Transform the list of strings\n",
    "transform = count_vectorizer.fit_transform(data.posts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows list of stopwords\n",
    "#count_vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 4595)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandoned',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorbed',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'academic',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accused',\n",
       " 'achieve',\n",
       " 'acknowledge',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adhd',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'adopt',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advocate',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affects',\n",
       " 'affirmation',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'ak',\n",
       " 'ak0',\n",
       " 'aka',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'algebra',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'alright',\n",
       " 'alter',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambivert',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amused',\n",
       " 'amusing',\n",
       " 'analogy',\n",
       " 'analysis',\n",
       " 'analytical',\n",
       " 'analyze',\n",
       " 'analyzing',\n",
       " 'ancient',\n",
       " 'androgynous',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'anime',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoys',\n",
       " 'anonymous',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anti',\n",
       " 'antisocial',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apathetic',\n",
       " 'apathy',\n",
       " 'apologies',\n",
       " 'apologize',\n",
       " 'app',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'april',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arm',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'art',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'ashamed',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asperger',\n",
       " 'ass',\n",
       " 'assertive',\n",
       " 'assessment',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'assignment',\n",
       " 'assignments',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assumptions',\n",
       " 'astrology',\n",
       " 'ate',\n",
       " 'atheism',\n",
       " 'atheist',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'audience',\n",
       " 'aunt',\n",
       " 'aura',\n",
       " 'australia',\n",
       " 'authentic',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'autism',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'automatically',\n",
       " 'autumn',\n",
       " 'aux',\n",
       " 'auxiliary',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avatars',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'avoidance',\n",
       " 'avoidant',\n",
       " 'avoiding',\n",
       " 'aw',\n",
       " 'awake',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awkwardness',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'background',\n",
       " 'backwards',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'ball',\n",
       " 'balls',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'banned',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battle',\n",
       " 'bbc',\n",
       " 'bc',\n",
       " 'beach',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'beer',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'behave',\n",
       " 'behavior',\n",
       " 'behaviors',\n",
       " 'behaviour',\n",
       " 'beings',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'ben',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'bf',\n",
       " 'bi',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'billion',\n",
       " 'bills',\n",
       " 'biological',\n",
       " 'biology',\n",
       " 'bipolar',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bits',\n",
       " 'bitter',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'blend',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blogspot',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'blunt',\n",
       " 'blushed',\n",
       " 'board',\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'bold',\n",
       " 'bolded',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'books',\n",
       " 'borderline',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boredom',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'boss',\n",
       " 'bossy',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothering',\n",
       " 'bothers',\n",
       " 'bottle',\n",
       " 'bought',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'boundaries',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'bp',\n",
       " 'brain',\n",
       " 'brains',\n",
       " 'brand',\n",
       " 'brave',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breakup',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'briggs',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broad',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'browsing',\n",
       " 'brush',\n",
       " 'brutal',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'bubble',\n",
       " 'bubbly',\n",
       " 'buddy',\n",
       " 'bug',\n",
       " 'bugs',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bullied',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bullying',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bunny',\n",
       " 'burden',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burst',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterfly',\n",
       " 'button',\n",
       " 'buttons',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'cache',\n",
       " 'cafe',\n",
       " 'caffeine',\n",
       " 'cake',\n",
       " 'calculus',\n",
       " 'california',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'cancer',\n",
       " 'candy',\n",
       " 'capable',\n",
       " 'capacity',\n",
       " 'capitalism',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'career',\n",
       " 'careers',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'cares',\n",
       " 'caring',\n",
       " 'carl',\n",
       " 'carry',\n",
       " 'cars',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'castle',\n",
       " 'casual',\n",
       " 'casually',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'categories',\n",
       " 'category',\n",
       " 'catholic',\n",
       " 'cats',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causes',\n",
       " 'causing',\n",
       " 'cautious',\n",
       " 'cave',\n",
       " 'cdn',\n",
       " 'celebrate',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'centered',\n",
       " 'central',\n",
       " 'cents',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'certainty',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'chameleon',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'chaotic',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'characteristic',\n",
       " 'characteristics',\n",
       " 'characters',\n",
       " 'charge',\n",
       " 'charismatic',\n",
       " 'charlie',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chasing',\n",
       " 'chat',\n",
       " 'chatting',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'cheated',\n",
       " 'cheating',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheer',\n",
       " 'cheers',\n",
       " 'cheese',\n",
       " 'cheesy',\n",
       " 'chemical',\n",
       " 'chemistry',\n",
       " 'chess',\n",
       " 'chest',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'choosing',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christianity',\n",
       " 'christians',\n",
       " 'christmas',\n",
       " 'church',\n",
       " 'cigarettes',\n",
       " 'circle',\n",
       " 'circles',\n",
       " 'circumstances',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'claiming',\n",
       " 'claims',\n",
       " 'clarification',\n",
       " 'clarify',\n",
       " 'clarity',\n",
       " 'clash',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'classical',\n",
       " 'classmates',\n",
       " 'classroom',\n",
       " 'clean',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'cliche',\n",
       " 'click',\n",
       " 'clicked',\n",
       " 'climbing',\n",
       " 'clingy',\n",
       " 'clinical',\n",
       " 'clip',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'clouds',\n",
       " 'club',\n",
       " 'clubs',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'clumsy',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cognitive',\n",
       " 'coincidence',\n",
       " 'cold',\n",
       " 'collect',\n",
       " 'collected',\n",
       " 'collection',\n",
       " 'collective',\n",
       " 'college',\n",
       " 'color',\n",
       " 'colored',\n",
       " 'colors',\n",
       " 'colour',\n",
       " 'colours',\n",
       " 'combination',\n",
       " 'combined',\n",
       " 'combo',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comforting',\n",
       " 'comic',\n",
       " 'comics',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'commented',\n",
       " 'comments',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'communicate',\n",
       " 'communicating',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'compassion',\n",
       " 'compassionate',\n",
       " 'compatibility',\n",
       " 'compatible',\n",
       " 'compelled',\n",
       " 'competent',\n",
       " 'competition',\n",
       " 'competitive',\n",
       " 'complain',\n",
       " 'complaining',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'compliment',\n",
       " 'compliments',\n",
       " 'comprehend',\n",
       " 'compromise',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'concentrate',\n",
       " 'concept',\n",
       " 'concepts',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerning',\n",
       " 'concerns',\n",
       " 'concert',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'concrete',\n",
       " 'condescending',\n",
       " 'condition',\n",
       " 'conditions',\n",
       " 'confess',\n",
       " 'confession',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confirmed',\n",
       " 'conflict',\n",
       " 'conflicts',\n",
       " 'conform',\n",
       " 'confront',\n",
       " 'confrontation',\n",
       " 'confuse',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'confusion',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connecting',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'cons',\n",
       " 'conscious',\n",
       " 'consciously',\n",
       " 'consciousness',\n",
       " 'consensus',\n",
       " 'consequences',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'considerate',\n",
       " 'consideration',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consistency',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'construct',\n",
       " 'constructive',\n",
       " 'contact',\n",
       " 'contemplating',\n",
       " 'content',\n",
       " 'context',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'contradictory',\n",
       " 'contrary',\n",
       " 'contrast',\n",
       " 'contribute',\n",
       " 'control',\n",
       " 'controlled',\n",
       " 'controlling',\n",
       " 'conventional',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'convey',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'convincing',\n",
       " 'cook',\n",
       " 'cookie',\n",
       " 'cookies',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'cope',\n",
       " 'coping',\n",
       " 'copy',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'corporate',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'correlation',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'couch',\n",
       " 'cough',\n",
       " 'couldn',\n",
       " 'counseling',\n",
       " 'counselor',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counting',\n",
       " 'countless',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'couple',\n",
       " 'courage',\n",
       " 'course',\n",
       " 'courses',\n",
       " 'cousin',\n",
       " 'cousins',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'coworker',\n",
       " 'coworkers',\n",
       " 'crack',\n",
       " 'cracked',\n",
       " 'crap',\n",
       " 'crappy',\n",
       " 'crash',\n",
       " 'crave',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'creation',\n",
       " 'creative',\n",
       " 'creativity',\n",
       " 'creator',\n",
       " 'creature',\n",
       " 'creatures',\n",
       " 'credit',\n",
       " 'creep',\n",
       " 'creepy',\n",
       " 'cried',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'cringe',\n",
       " 'crisis',\n",
       " 'criteria',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'criticize',\n",
       " 'cross',\n",
       " 'crossed',\n",
       " 'crowd',\n",
       " 'crowds',\n",
       " 'cruel',\n",
       " 'crush',\n",
       " 'crushes',\n",
       " 'crushing',\n",
       " 'crying',\n",
       " 'cuddle',\n",
       " 'cuddling',\n",
       " 'cuddly',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cultures',\n",
       " 'cup',\n",
       " 'cure',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curse',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutting',\n",
       " 'cuz',\n",
       " 'cycle',\n",
       " 'cynical',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dang',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'darker',\n",
       " 'darkness',\n",
       " 'darn',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dated',\n",
       " 'dates',\n",
       " 'dating',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'day',\n",
       " 'daydream',\n",
       " 'daydreaming',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'deals',\n",
       " 'dealt',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debate',\n",
       " 'debates',\n",
       " 'debating',\n",
       " 'decade',\n",
       " 'december',\n",
       " 'decent',\n",
       " 'decide',\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996541786743516\n"
     ]
    }
   ],
   "source": [
    "#deploy and evaluate model\n",
    "X=transform\n",
    "y= data.extroverted\n",
    "LogReg = LogisticRegression()\n",
    "log_model = LogReg.fit(X, y)\n",
    "print(LogReg.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LogReg.predict(X)\n",
    "from sklearn.metrics import classification_report\n",
    "#print(classification_report(y, y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99676557e-01, 3.23443127e-04],\n",
       "       [1.68976183e-01, 8.31023817e-01],\n",
       "       [9.91869069e-01, 8.13093107e-03],\n",
       "       ...,\n",
       "       [9.98742182e-01, 1.25781767e-03],\n",
       "       [9.46439716e-01, 5.35602838e-02],\n",
       "       [9.99435418e-01, 5.64581755e-04]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict probability\n",
    "LogReg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept is  [-0.99920886]\n",
      "Coefficients are [[ 0.07640115  0.47803825  0.0073766  ... -0.79152167 -0.33291049\n",
      "  -0.38872389]]\n"
     ]
    }
   ],
   "source": [
    "# Check trained model intercept\n",
    "print(\"Intercept is \",  log_model.intercept_)\n",
    "\n",
    "# Check trained model coefficients\n",
    "print(\"Coefficients are\",  log_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=LogReg, step=1, cv=StratifiedKFold(10),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit_model=sm.Logit(y,rfecv.transform(X))\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = rfecv.get_support()\n",
    "#Now support is an array, you can use that to efficiently extract the name of your selected features (columns). Make sure your feature names are in a numpy array, not a python list.\n",
    "\n",
    "feature_names = np.array(count_vectorizer.get_feature_names()) # transformed list to array\n",
    "\n",
    "feature_names_support = feature_names[support]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change max rows to show\n",
    "pd.options.display.max_rows =100\n",
    "pd.options.display.max_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame({'feature name':feature_names_support, 'coefficient': result.params})\n",
    "#https://stackoverflow.com/questions/13148429/how-to-change-the-order-of-dataframe-columns\n",
    "def order(frame,var):\n",
    "    if type(var) is str:\n",
    "        var = [var] #let the command take a string or list\n",
    "    varlist =[w for w in frame.columns if w not in var]\n",
    "    frame = frame[var+varlist]\n",
    "    return frame \n",
    "final = order(final, ['feature name'])\n",
    "final = final.sort_values('coefficient', ascending = False)\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
