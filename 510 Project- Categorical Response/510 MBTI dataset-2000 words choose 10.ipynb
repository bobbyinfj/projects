{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dataset\n",
    "data= pd.read_csv(r'C:\\Users\\Robert\\Desktop\\mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>extroverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts extroverted\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           I\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...           E\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           I\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           I\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...           E"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add a column to specify if extroverted.\n",
    "data['extroverted']= data.type.str[:1]\n",
    "#df['New_Sample'] = df.Sample.str[:1]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>extroverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8675</td>\n",
       "      <td>8675</td>\n",
       "      <td>8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>16</td>\n",
       "      <td>8675</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Same... haha xD  I would try to give advice o...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1832</td>\n",
       "      <td>1</td>\n",
       "      <td>6676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts extroverted\n",
       "count   8675                                               8675        8675\n",
       "unique    16                                               8675           2\n",
       "top     INFP  'Same... haha xD  I would try to give advice o...           I\n",
       "freq    1832                                                  1        6676"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many is I vs. E in dataset?\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">extroverted</th>\n",
       "      <th colspan=\"4\" halign=\"left\">posts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENFJ</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>You are a Benevolent Visionary.   You are a Vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENFP</th>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>675</td>\n",
       "      <td>675</td>\n",
       "      <td>675</td>\n",
       "      <td>Whats your instinctual variant in enneagram?||...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTJ</th>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>'Well, I think healthy ISTPs who are good at w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTP</th>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>'You are 47.2% Good.  You are 38.5% Lawful.  A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFJ</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>'The Death Cure by James Dashner (final book o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFP</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>'INTP because you're paranoid and logical and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTJ</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>'When healthy Threes go to Six, they become co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTP</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>Splinter Cell Blacklist for Xbox 360.|||ESTPs ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFJ</th>\n",
       "      <td>1470</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470</td>\n",
       "      <td>'24|||INFJs have loads of inner demons, which ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFP</th>\n",
       "      <td>1832</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1832</td>\n",
       "      <td>1832</td>\n",
       "      <td>1832</td>\n",
       "      <td>'I feel happy for no obvious reason.|||I'm a f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1091</td>\n",
       "      <td>1091</td>\n",
       "      <td>1091</td>\n",
       "      <td>'Online, for the most part.  I only go out if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTP</th>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1304</td>\n",
       "      <td>1304</td>\n",
       "      <td>1304</td>\n",
       "      <td>'Take the C.|||then you must hate me...because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFJ</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>'Maker, then Survivor|||The air is so quiet......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFP</th>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>'So I've been noticing like the past week or s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTJ</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>My girlfriend tells me I can't take a hint, bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTP</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>'No emotional guilt here over anything at all....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     extroverted                  posts         \\\n",
       "           count unique top  freq count unique   \n",
       "type                                             \n",
       "ENFJ         190      1   E   190   190    190   \n",
       "ENFP         675      1   E   675   675    675   \n",
       "ENTJ         231      1   E   231   231    231   \n",
       "ENTP         685      1   E   685   685    685   \n",
       "ESFJ          42      1   E    42    42     42   \n",
       "ESFP          48      1   E    48    48     48   \n",
       "ESTJ          39      1   E    39    39     39   \n",
       "ESTP          89      1   E    89    89     89   \n",
       "INFJ        1470      1   I  1470  1470   1470   \n",
       "INFP        1832      1   I  1832  1832   1832   \n",
       "INTJ        1091      1   I  1091  1091   1091   \n",
       "INTP        1304      1   I  1304  1304   1304   \n",
       "ISFJ         166      1   I   166   166    166   \n",
       "ISFP         271      1   I   271   271    271   \n",
       "ISTJ         205      1   I   205   205    205   \n",
       "ISTP         337      1   I   337   337    337   \n",
       "\n",
       "                                                              \n",
       "                                                    top freq  \n",
       "type                                                          \n",
       "ENFJ  You are a Benevolent Visionary.   You are a Vi...    1  \n",
       "ENFP  Whats your instinctual variant in enneagram?||...    1  \n",
       "ENTJ  'Well, I think healthy ISTPs who are good at w...    1  \n",
       "ENTP  'You are 47.2% Good.  You are 38.5% Lawful.  A...    1  \n",
       "ESFJ  'The Death Cure by James Dashner (final book o...    1  \n",
       "ESFP  'INTP because you're paranoid and logical and ...    1  \n",
       "ESTJ  'When healthy Threes go to Six, they become co...    1  \n",
       "ESTP  Splinter Cell Blacklist for Xbox 360.|||ESTPs ...    1  \n",
       "INFJ  '24|||INFJs have loads of inner demons, which ...    1  \n",
       "INFP  'I feel happy for no obvious reason.|||I'm a f...    1  \n",
       "INTJ  'Online, for the most part.  I only go out if ...    1  \n",
       "INTP  'Take the C.|||then you must hate me...because...    1  \n",
       "ISFJ  'Maker, then Survivor|||The air is so quiet......    1  \n",
       "ISFP  'So I've been noticing like the past week or s...    1  \n",
       "ISTJ  My girlfriend tells me I can't take a hint, bu...    1  \n",
       "ISTP  'No emotional guilt here over anything at all....    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#breakdown of types in survery\n",
    "type_data = data.groupby('type')\n",
    "type_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>extroverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts extroverted\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           0\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...           1\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           0\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           0\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['extroverted'].replace(['I','E'],['0','1'],inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type           object\n",
       "posts          object\n",
       "extroverted    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['extroverted'] = data['extroverted'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type           object\n",
       "posts          object\n",
       "extroverted     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(['http', 'isfj', 'infp', 'intj', 'https', 'youtube', 'enfp', 'entp',\n",
    "                                            'infj', 'infp', 'intj','intp',\n",
    " 'intp','istj', 'istp', '00', 'enfps', 'entps', 'infjs', 'enfjs', 'estps',\n",
    "                                            'entj', 'esfjs', 'existence', 'infps', 'enfj', 'entjs', 'intps',\n",
    " '000',\n",
    " '01',\n",
    " '02',\n",
    " '03',\n",
    " '04',\n",
    " '05',\n",
    " '06',\n",
    " '07',\n",
    " '08',\n",
    " '09',\n",
    " '10',\n",
    " '100',\n",
    " '1000',\n",
    " '101',\n",
    " '10th',\n",
    " '11',\n",
    " '110',\n",
    " '11th',\n",
    " '12',\n",
    " '120',\n",
    " '13',\n",
    " '130',\n",
    " '14',\n",
    " '140',\n",
    " '15',\n",
    " '150',\n",
    " '16',\n",
    " '16personalities',\n",
    " '17',\n",
    " '18',\n",
    " '180',\n",
    " '19',\n",
    " '1984',\n",
    " '1995',\n",
    " '1s',\n",
    " '1st',\n",
    " '1w2',\n",
    " '1w9',\n",
    " '20',\n",
    " '200',\n",
    " '2000',\n",
    " '2001',\n",
    " '2005',\n",
    " '2006',\n",
    " '2007',\n",
    " '2008',\n",
    " '2009',\n",
    " '2010',\n",
    " '2011',\n",
    " '2012',\n",
    " '2013',\n",
    " '2014',\n",
    " '2015',\n",
    " '2016',\n",
    " '2017',\n",
    " '20s',\n",
    " '20th',\n",
    " '21',\n",
    " '21st',\n",
    " '22',\n",
    " '23',\n",
    " '24',\n",
    " '25',\n",
    " '26',\n",
    " '27',\n",
    " '28',\n",
    " '29',\n",
    " '2nd',\n",
    " '2w1',\n",
    " '2w3',\n",
    " '30',\n",
    " '300',\n",
    " '30s',\n",
    " '31',\n",
    " '32',\n",
    " '33',\n",
    " '34',\n",
    " '35',\n",
    " '36',\n",
    " '37',\n",
    " '38',\n",
    " '39',\n",
    " '3D',\n",
    " '3rd',\n",
    " '3s',\n",
    " '3w2',\n",
    " '3w4',\n",
    " '40',\n",
    " '400',\n",
    " '41',\n",
    " '42',\n",
    " '43',\n",
    " '44',\n",
    " '45',\n",
    " '46',\n",
    " '47',\n",
    " '48',\n",
    " '49',\n",
    " '4s',\n",
    " '4th',\n",
    " '4w3',\n",
    " '4w5',\n",
    " '50',\n",
    " '500',\n",
    " '51',\n",
    " '52',\n",
    " '53',\n",
    " '54',\n",
    " '55',\n",
    " '56',\n",
    " '564x',\n",
    " '57',\n",
    " '58',\n",
    " '59',\n",
    " '5s',\n",
    " '5th',\n",
    " '5w4',\n",
    " '5w6',\n",
    " '60',\n",
    " '600',\n",
    " '60s',\n",
    " '61',\n",
    " '62',\n",
    " '63',\n",
    " '64',\n",
    " '65',\n",
    " '66',\n",
    " '67',\n",
    " '68',\n",
    " '69',\n",
    " '6s',\n",
    " '6th',\n",
    " '6w5',\n",
    " '6w7',\n",
    " '70',\n",
    " '70s',\n",
    " '71',\n",
    " '72',\n",
    " '73',\n",
    " '736x',\n",
    " '74',\n",
    " '75',\n",
    " '76',\n",
    " '77',\n",
    " '78',\n",
    " '79',\n",
    " '7s',\n",
    " '7th',\n",
    " '7w6',\n",
    " '7w8',\n",
    " '80',\n",
    " '80s',\n",
    " '81',\n",
    " '82',\n",
    " '83',\n",
    " '84',\n",
    " '85',\n",
    " '86',\n",
    " '87',\n",
    " '88',\n",
    " '89',\n",
    " '8s',\n",
    " '8th',\n",
    " '8w7',\n",
    " '8w9',\n",
    " '90',\n",
    " '90s',\n",
    " '91',\n",
    " '92',\n",
    " '94',\n",
    " '95',\n",
    " '98',\n",
    " '99',\n",
    " '9s',\n",
    " '9th',\n",
    " '9w1',\n",
    " '9w8', '125',\n",
    " '160',\n",
    " '2003',\n",
    " '2004',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create our count vectorizer\n",
    "count_vectorizer = CountVectorizer(analyzer='word', min_df=1, stop_words = stop_words, lowercase=True,max_features=2000)\n",
    "\n",
    "#Transform the list of strings\n",
    "transform = count_vectorizer.fit_transform(data.posts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'00',\n",
       "           '000',\n",
       "           '01',\n",
       "           '02',\n",
       "           '03',\n",
       "           '04',\n",
       "           '05',\n",
       "           '06',\n",
       "           '07',\n",
       "           '08',\n",
       "           '09',\n",
       "           '10',\n",
       "           '100',\n",
       "           '1000',\n",
       "           '101',\n",
       "           '10th',\n",
       "           '11',\n",
       "           '110',\n",
       "           '11th',\n",
       "           '12',\n",
       "           '120',\n",
       "           '125',\n",
       "           '13',\n",
       "           '130',\n",
       "           '14',\n",
       "           '140',\n",
       "           '15',\n",
       "           '150',\n",
       "           '16',\n",
       "           '160',\n",
       "           '16personalities',\n",
       "           '17',\n",
       "           '18',\n",
       "           '180',\n",
       "           '19',\n",
       "           '1984',\n",
       "           '1995',\n",
       "           '1s',\n",
       "           '1st',\n",
       "           '1w2',\n",
       "           '1w9',\n",
       "           '20',\n",
       "           '200',\n",
       "           '2000',\n",
       "           '2001',\n",
       "           '2003',\n",
       "           '2004',\n",
       "           '2005',\n",
       "           '2006',\n",
       "           '2007',\n",
       "           '2008',\n",
       "           '2009',\n",
       "           '2010',\n",
       "           '2011',\n",
       "           '2012',\n",
       "           '2013',\n",
       "           '2014',\n",
       "           '2015',\n",
       "           '2016',\n",
       "           '2017',\n",
       "           '20s',\n",
       "           '20th',\n",
       "           '21',\n",
       "           '21st',\n",
       "           '22',\n",
       "           '23',\n",
       "           '24',\n",
       "           '25',\n",
       "           '26',\n",
       "           '27',\n",
       "           '28',\n",
       "           '29',\n",
       "           '2nd',\n",
       "           '2w1',\n",
       "           '2w3',\n",
       "           '30',\n",
       "           '300',\n",
       "           '30s',\n",
       "           '31',\n",
       "           '32',\n",
       "           '33',\n",
       "           '34',\n",
       "           '35',\n",
       "           '36',\n",
       "           '37',\n",
       "           '38',\n",
       "           '39',\n",
       "           '3D',\n",
       "           '3rd',\n",
       "           '3s',\n",
       "           '3w2',\n",
       "           '3w4',\n",
       "           '40',\n",
       "           '400',\n",
       "           '41',\n",
       "           '42',\n",
       "           '43',\n",
       "           '44',\n",
       "           '45',\n",
       "           '46',\n",
       "           '47',\n",
       "           '48',\n",
       "           '49',\n",
       "           '4s',\n",
       "           '4th',\n",
       "           '4w3',\n",
       "           '4w5',\n",
       "           '50',\n",
       "           '500',\n",
       "           '51',\n",
       "           '52',\n",
       "           '53',\n",
       "           '54',\n",
       "           '55',\n",
       "           '56',\n",
       "           '564x',\n",
       "           '57',\n",
       "           '58',\n",
       "           '59',\n",
       "           '5s',\n",
       "           '5th',\n",
       "           '5w4',\n",
       "           '5w6',\n",
       "           '60',\n",
       "           '600',\n",
       "           '60s',\n",
       "           '61',\n",
       "           '62',\n",
       "           '63',\n",
       "           '64',\n",
       "           '65',\n",
       "           '66',\n",
       "           '67',\n",
       "           '68',\n",
       "           '69',\n",
       "           '6s',\n",
       "           '6th',\n",
       "           '6w5',\n",
       "           '6w7',\n",
       "           '70',\n",
       "           '70s',\n",
       "           '71',\n",
       "           '72',\n",
       "           '73',\n",
       "           '736x',\n",
       "           '74',\n",
       "           '75',\n",
       "           '76',\n",
       "           '77',\n",
       "           '78',\n",
       "           '79',\n",
       "           '7s',\n",
       "           '7th',\n",
       "           '7w6',\n",
       "           '7w8',\n",
       "           '80',\n",
       "           '80s',\n",
       "           '81',\n",
       "           '82',\n",
       "           '83',\n",
       "           '84',\n",
       "           '85',\n",
       "           '86',\n",
       "           '87',\n",
       "           '88',\n",
       "           '89',\n",
       "           '8s',\n",
       "           '8th',\n",
       "           '8w7',\n",
       "           '8w9',\n",
       "           '90',\n",
       "           '90s',\n",
       "           '91',\n",
       "           '92',\n",
       "           '94',\n",
       "           '95',\n",
       "           '98',\n",
       "           '99',\n",
       "           '9s',\n",
       "           '9th',\n",
       "           '9w1',\n",
       "           '9w8',\n",
       "           'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enfj',\n",
       "           'enfjs',\n",
       "           'enfp',\n",
       "           'enfps',\n",
       "           'enough',\n",
       "           'entj',\n",
       "           'entjs',\n",
       "           'entp',\n",
       "           'entps',\n",
       "           'esfjs',\n",
       "           'estps',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'existence',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'http',\n",
       "           'https',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'infj',\n",
       "           'infjs',\n",
       "           'infp',\n",
       "           'infps',\n",
       "           'interest',\n",
       "           'intj',\n",
       "           'into',\n",
       "           'intp',\n",
       "           'intps',\n",
       "           'is',\n",
       "           'isfj',\n",
       "           'istj',\n",
       "           'istp',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves',\n",
       "           'youtube'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [2, 1, 0, ..., 0, 1, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 2000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abstract',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'achieve',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'adhd',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'adorable',\n",
       " 'adult',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'afraid',\n",
       " 'age',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'air',\n",
       " 'ak',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alive',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'alot',\n",
       " 'alright',\n",
       " 'alternative',\n",
       " 'amazing',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amp',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'analyzing',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'anime',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anti',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyways',\n",
       " 'apart',\n",
       " 'apologize',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appears',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arrogant',\n",
       " 'art',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'arts',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'asshole',\n",
       " 'associated',\n",
       " 'assume',\n",
       " 'assuming',\n",
       " 'atheist',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'authority',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'baby',\n",
       " 'background',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'band',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'bed',\n",
       " 'beer',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'benefit',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'bible',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'blue',\n",
       " 'blunt',\n",
       " 'blushed',\n",
       " 'board',\n",
       " 'body',\n",
       " 'book',\n",
       " 'books',\n",
       " 'borderline',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'boss',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothers',\n",
       " 'bought',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'brain',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'briggs',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'brings',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'btw',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bullshit',\n",
       " 'bunch',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'capable',\n",
       " 'car',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'cares',\n",
       " 'caring',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'cats',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causes',\n",
       " 'cdn',\n",
       " 'center',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'character',\n",
       " 'characteristics',\n",
       " 'characters',\n",
       " 'charming',\n",
       " 'chat',\n",
       " 'check',\n",
       " 'cheese',\n",
       " 'chemistry',\n",
       " 'chicken',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'chose',\n",
       " 'christian',\n",
       " 'christmas',\n",
       " 'church',\n",
       " 'circle',\n",
       " 'circumstances',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'classical',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'click',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'clothes',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cognitive',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'color',\n",
       " 'colors',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'comments',\n",
       " 'common',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'compliment',\n",
       " 'compliments',\n",
       " 'computer',\n",
       " 'concept',\n",
       " 'concerned',\n",
       " 'conclusion',\n",
       " 'concrete',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'conflict',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'congrats',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'conscious',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'context',\n",
       " 'continue',\n",
       " 'control',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'convinced',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'correlation',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'crap',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'creative',\n",
       " 'creativity',\n",
       " 'creepy',\n",
       " 'cried',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'crush',\n",
       " 'crying',\n",
       " 'culture',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cuz',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dangerous',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dated',\n",
       " 'dating',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debate',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deeply',\n",
       " 'define',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'delete',\n",
       " 'depending',\n",
       " 'depends',\n",
       " 'depressed',\n",
       " 'depression',\n",
       " 'depth',\n",
       " 'described',\n",
       " 'describes',\n",
       " 'describing',\n",
       " 'description',\n",
       " 'descriptions',\n",
       " 'deserve',\n",
       " 'design',\n",
       " 'desire',\n",
       " 'despite',\n",
       " 'details',\n",
       " 'determine',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'development',\n",
       " 'diagnosed',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'difference',\n",
       " 'differences',\n",
       " 'different',\n",
       " 'differently',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'disagree',\n",
       " 'disappointed',\n",
       " 'discovered',\n",
       " 'discuss',\n",
       " 'discussing',\n",
       " 'discussion',\n",
       " 'dislike',\n",
       " 'disorder',\n",
       " 'distance',\n",
       " 'distant',\n",
       " 'doctor',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'doing',\n",
       " 'dom',\n",
       " 'dominant',\n",
       " 'doms',\n",
       " 'don',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'dr',\n",
       " 'drama',\n",
       " 'draw',\n",
       " 'drawing',\n",
       " 'drawn',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'dress',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'drives',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'dude',\n",
       " 'dumb',\n",
       " 'dunno',\n",
       " 'dying',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'edit',\n",
       " 'education',\n",
       " 'effect',\n",
       " 'effects',\n",
       " 'effort',\n",
       " 'ego',\n",
       " 'eh',\n",
       " 'elaborate',\n",
       " 'em',\n",
       " 'email',\n",
       " 'emotion',\n",
       " 'emotional',\n",
       " 'emotionally',\n",
       " 'emotions',\n",
       " 'empathy',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'energy',\n",
       " 'engage',\n",
       " 'engineering',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enneagram',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'environment',\n",
       " 'episode',\n",
       " 'equal',\n",
       " 'equally',\n",
       " 'escape',\n",
       " 'esfj',\n",
       " 'esfp',\n",
       " 'especially',\n",
       " 'essentially',\n",
       " 'esteem',\n",
       " 'estj',\n",
       " 'estjs',\n",
       " 'estp',\n",
       " 'event',\n",
       " 'events',\n",
       " 'eventually',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'evidence',\n",
       " 'evil',\n",
       " 'ex',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'examples',\n",
       " 'excellent',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'excuse',\n",
       " 'exercise',\n",
       " 'exist',\n",
       " 'exists',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiences',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'explains',\n",
       " 'explanation',\n",
       " 'explore',\n",
       " 'express',\n",
       " 'expressing',\n",
       " 'expression',\n",
       " 'extent',\n",
       " 'external',\n",
       " 'extra',\n",
       " 'extraverted',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'extroversion',\n",
       " 'extrovert',\n",
       " 'extroverted',\n",
       " 'extroverts',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'faces',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'factors',\n",
       " 'facts',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'faith',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'far',\n",
       " 'fascinating',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fault',\n",
       " 'favorite',\n",
       " 'favorites',\n",
       " 'favourite',\n",
       " 'fbcdn',\n",
       " 'fe',\n",
       " 'fear',\n",
       " 'feature',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'feeler',\n",
       " 'feelers',\n",
       " 'feeling',\n",
       " 'feelings',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'females',\n",
       " 'feminine',\n",
       " 'fi',\n",
       " 'fiction',\n",
       " 'fictional',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'figured',\n",
       " 'files',\n",
       " 'filled',\n",
       " 'film',\n",
       " 'films',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'fish',\n",
       " 'fit',\n",
       " 'fits',\n",
       " 'fix',\n",
       " 'flaws',\n",
       " 'flirt',\n",
       " 'flirting',\n",
       " 'flow',\n",
       " 'fly',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'food',\n",
       " 'force',\n",
       " 'forced',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgive',\n",
       " 'forgot',\n",
       " 'form',\n",
       " 'forth',\n",
       " 'forum',\n",
       " 'forums',\n",
       " 'forward',\n",
       " 'freak',\n",
       " 'freaking',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'french',\n",
       " 'frequently',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'friendships',\n",
       " 'frustrated',\n",
       " 'frustrating',\n",
       " 'fuck',\n",
       " 'fucking',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'function',\n",
       " 'functions',\n",
       " 'funny',\n",
       " 'future',\n",
       " 'gain',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'gender',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'genius',\n",
       " 'genuine',\n",
       " 'genuinely',\n",
       " 'german',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'gif',\n",
       " 'gift',\n",
       " 'gifts',\n",
       " 'giphy',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'goal',\n",
       " 'goals',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'google',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'gotten',\n",
       " 'government',\n",
       " 'grade',\n",
       " 'grades',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'greatest',\n",
       " 'green',\n",
       " 'grew',\n",
       " 'grey',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'grow',\n",
       " 'growing',\n",
       " 'grown',\n",
       " 'guess',\n",
       " 'guessing',\n",
       " 'guilty',\n",
       " 'guitar',\n",
       " 'gut',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'ha',\n",
       " 'habit',\n",
       " 'hadn',\n",
       " 'haha',\n",
       " 'hahaha',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'handle',\n",
       " 'hands',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'harder',\n",
       " 'hardly',\n",
       " 'harry',\n",
       " 'harsh',\n",
       " 'hasn',\n",
       " 'hate',\n",
       " 'hated',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'head',\n",
       " 'heads',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'heavy',\n",
       " 'heh',\n",
       " 'hehe',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'helpful',\n",
       " 'helping',\n",
       " 'helps',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hidden',\n",
       " 'hide',\n",
       " 'hiding',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hm',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hobbies',\n",
       " 'hold',\n",
       " 'holding',\n",
       " 'holy',\n",
       " 'home',\n",
       " 'homework',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'honesty',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hoping',\n",
       " 'horrible',\n",
       " 'horror',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'html',\n",
       " 'hug',\n",
       " 'huge',\n",
       " 'hugs',\n",
       " 'huh',\n",
       " 'human',\n",
       " 'humanity',\n",
       " 'humans',\n",
       " 'humor',\n",
       " 'hurt',\n",
       " 'hurts',\n",
       " 'husband',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ideal',\n",
       " 'ideas',\n",
       " 'identify',\n",
       " 'identity',\n",
       " 'idiot',\n",
       " 'idk',\n",
       " 'ignore',\n",
       " 'ill',\n",
       " 'illness',\n",
       " 'im',\n",
       " 'image',\n",
       " 'images',\n",
       " 'imagination',\n",
       " 'imagine',\n",
       " 'imgur',\n",
       " 'immature',\n",
       " 'immediately',\n",
       " 'imo',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impression',\n",
       " 'improve',\n",
       " 'include',\n",
       " 'including',\n",
       " 'incredibly',\n",
       " 'independent',\n",
       " 'index',\n",
       " 'individual',\n",
       " 'individuals',\n",
       " 'inferior',\n",
       " 'influence',\n",
       " 'info',\n",
       " 'information',\n",
       " 'initially',\n",
       " 'inner',\n",
       " 'input',\n",
       " 'insane',\n",
       " 'insecure',\n",
       " 'inside',\n",
       " 'insight',\n",
       " 'insightful',\n",
       " 'instance',\n",
       " 'instead',\n",
       " 'instinct',\n",
       " 'intellectual',\n",
       " 'intelligence',\n",
       " 'intelligent',\n",
       " 'intense',\n",
       " 'interact',\n",
       " 'interaction',\n",
       " 'interactions',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'interests',\n",
       " 'internal',\n",
       " 'internet',\n",
       " 'interview',\n",
       " 'intjs',\n",
       " 'introversion',\n",
       " 'introvert',\n",
       " 'introverted',\n",
       " 'introverts',\n",
       " 'intuition',\n",
       " 'intuitive',\n",
       " 'involved',\n",
       " 'iphone',\n",
       " 'iq',\n",
       " 'irl',\n",
       " 'irrational',\n",
       " 'isfjs',\n",
       " 'isfp',\n",
       " 'isfps',\n",
       " 'ish',\n",
       " 'isn',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'istjs',\n",
       " 'istps',\n",
       " 'ive',\n",
       " 'jack',\n",
       " 'japanese',\n",
       " 'jealous',\n",
       " 'jesus',\n",
       " 'job',\n",
       " 'jobs',\n",
       " 'john',\n",
       " 'join',\n",
       " 'joined',\n",
       " 'joke',\n",
       " 'jokes',\n",
       " 'joking',\n",
       " 'joy',\n",
       " 'jpg',\n",
       " 'judge',\n",
       " 'judging',\n",
       " 'jump',\n",
       " 'jung',\n",
       " 'just',\n",
       " 'keeping',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'key',\n",
       " 'kick',\n",
       " 'kid',\n",
       " 'kidding',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killing',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'kinds',\n",
       " 'king',\n",
       " 'kiss',\n",
       " 'kitteh',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knowing',\n",
       " 'knowledge',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'lack',\n",
       " 'lady',\n",
       " 'laid',\n",
       " 'land',\n",
       " 'language',\n",
       " 'languages',\n",
       " 'large',\n",
       " 'late',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880576368876\n"
     ]
    }
   ],
   "source": [
    "#deploy and evaluate model\n",
    "X=transform\n",
    "y= data.extroverted\n",
    "LogReg = LogisticRegression()\n",
    "log_model = LogReg.fit(X, y)\n",
    "print(LogReg.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LogReg.predict(X)\n",
    "from sklearn.metrics import classification_report\n",
    "#print(classification_report(y, y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99449271,  0.00550729],\n",
       "       [ 0.28329733,  0.71670267],\n",
       "       [ 0.98574551,  0.01425449],\n",
       "       ..., \n",
       "       [ 0.94706755,  0.05293245],\n",
       "       [ 0.88074853,  0.11925147],\n",
       "       [ 0.91951458,  0.08048542]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict probability\n",
    "LogReg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept is  [-0.90342231]\n",
      "Coefficients are [[-0.06996761  0.06183464  0.06258491 ..., -0.04813134 -0.11376113\n",
      "  -0.3291221 ]]\n"
     ]
    }
   ],
   "source": [
    "# Check trained model intercept\n",
    "print(\"Intercept is \",  log_model.intercept_)\n",
    "\n",
    "# Check trained model coefficients\n",
    "print(\"Coefficients are\",  log_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ..., False False False]\n",
      "[1343  993 1431 ..., 1538 1257  137]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(LogReg, 10)\n",
    "rfe = rfe.fit(X, y)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rfe.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#support = rfe.support_\n",
    "#Now support is an array, you can use that to efficiently extract the name of your selected features (columns). Make sure your feature names are in a numpy array, not a python list.\n",
    "\n",
    "#feature_names = np.array(count_vectorizer.get_feature_names()) # transformed list to array\n",
    "\n",
    "#feature_names[support]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print ('coefficients',rfe.estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'words': feature_names[support], 'coefficients': rfe.estimator_.coef_})\n",
    "#df\n",
    "\n",
    "#rfe.estimator_.coef_.shape\n",
    "#feature_names[support].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#broken\n",
    "#cols = X[support]\n",
    "#X=X[cols]\n",
    "#y=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.631348\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            extroverted   No. Observations:                 8675\n",
      "Model:                          Logit   Df Residuals:                     8665\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Sat, 28 Apr 2018   Pseudo R-squ.:                 -0.1696\n",
      "Time:                        23:44:14   Log-Likelihood:                -5476.9\n",
      "converged:                       True   LL-Null:                       -4682.7\n",
      "                                        LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.1181      0.101     -1.175      0.240      -0.315       0.079\n",
      "x2            -0.0087      0.079     -0.110      0.912      -0.164       0.146\n",
      "x3            -1.3956      0.139    -10.010      0.000      -1.669      -1.122\n",
      "x4            -1.1885      0.134     -8.887      0.000      -1.451      -0.926\n",
      "x5            -1.2201      0.155     -7.864      0.000      -1.524      -0.916\n",
      "x6            -1.3557      0.145     -9.349      0.000      -1.640      -1.071\n",
      "x7            -1.2474      0.125     -9.964      0.000      -1.493      -1.002\n",
      "x8            -0.1335      0.074     -1.816      0.069      -0.278       0.011\n",
      "x9            -1.2627      0.134     -9.426      0.000      -1.525      -1.000\n",
      "x10           -1.3425      0.145     -9.264      0.000      -1.626      -1.058\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model=sm.Logit(y,rfe.transform(X))\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
